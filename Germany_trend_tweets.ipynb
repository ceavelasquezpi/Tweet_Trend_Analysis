{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trending tweets retrieving - Germany"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<twitter.api.Twitter object at 0x00000281BE4C13A0>\n"
     ]
    }
   ],
   "source": [
    "import twitter\n",
    "\n",
    "# Go to https://developer.twitter.com/en/apps to create an app and get values\n",
    "# for these credentials, which you'll need to provide in place of these\n",
    "# empty string values that are defined as placeholders.\n",
    "# See https://developer.twitter.com/en/docs/basics/authentication/overview/oauth\n",
    "# for more information on Twitter's OAuth implementation.\n",
    "\n",
    "# insert your keys below\n",
    "CONSUMER_KEY = ''   # Key associated with the application\n",
    "CONSUMER_SECRET = '' # Password used to authenticate with the authentication server\n",
    "OAUTH_TOKEN = '' # Key given to the client after successful authentication of above keys\n",
    "OAUTH_TOKEN_SECRET = '' # Password for the access key\n",
    "\n",
    "# create an object called auth that represents your OAuth authorization\n",
    "auth = twitter.oauth.OAuth(OAUTH_TOKEN, OAUTH_TOKEN_SECRET,\n",
    "                           CONSUMER_KEY, CONSUMER_SECRET)\n",
    "\n",
    "# auth object is passed to a class called Twitter that is capable of issuing queries to Twitter’s API.\n",
    "twitter_api = twitter.Twitter(auth=auth)\n",
    "\n",
    "# Nothing to see by displaying twitter_api object except that it's now a\n",
    "# defined variable. \n",
    "# It indicates that you’ve successfully used OAuth credentials to gain authorization to query Twitter’s API.\n",
    "\n",
    "print(twitter_api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrieving the trends for Germany using the Twitter API and the geocode for the API for Germany\n",
    "\n",
    "# See https://dev.twitter.com/docs/api/1.1/get/trends/place and\n",
    "# http://developer.yahoo.com/geo/geoplanet/\n",
    "\n",
    "DE_WOE_ID = 23424829 #Geocode for Germany\n",
    "\n",
    "\n",
    "# Prefix ID with the underscore for query string parameterization.\n",
    "# Without the underscore, the twitter package appends the ID value\n",
    "# to the URL itself as a special case keyword argument.\n",
    "\n",
    "de_trends = twitter_api.trends.place(_id=DE_WOE_ID)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trend_names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [trend_names]\n",
       "Index: []"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The idea behind the base file 'trend_names_base_ger.xlsx' is to add to a base excel file hard-coded trends to iterate over to retrieve tweets.\n",
    "# The found trends would be also searched over on top of it. Unlike the case for Colombia. \n",
    "# In practice, only the API retrieved trends were considered, and therefore this base file is an empty excel file (only with the trend_names header)\n",
    "\n",
    "stored_trend_names = pd.read_excel('trend_names_base_ger.xlsx')\n",
    "stored_trend_names = stored_trend_names.drop(columns=['Unnamed: 0'])\n",
    "stored_trend_names.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_trend_names = stored_trend_names.trend_names.values.tolist()\n",
    "#previous_trend_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trend_names = []\n",
    "for trend in de_trends[0]['trends']:\n",
    "    trend_names.append(trend['name']) #Appending all retrieved trends to a list\n",
    "#trend_names\n",
    "\n",
    "for trend in trend_names: #For each trends retrieved, check if it is not already on the list, to have only unique ones\n",
    "    if trend not in previous_trend_names:\n",
    "        print('added', trend, 'to trend_names to mine tweets')\n",
    "        previous_trend_names.append(trend)\n",
    "trends_to_save = previous_trend_names.copy() #This is the final list with the trends_names to save on a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save trend names\n",
    "now = datetime.datetime.now().strftime(\"%m.%d.%Y_%Hh\")\n",
    "name = 'Trend_names_germany_{}.xlsx'.format(now)\n",
    "pd.DataFrame({'trend_names':trends_to_save}).to_excel(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieving tweets for each trending topic and relevant information for each of those tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important note:** The- folowing two block of code generate a dictionary with data from the tweets corresponding to each trending topic. This data will be stored in files formatted with the datetime of retrieval for later processing in the \"Tweet_analysis.ipynb\" file. For Germany, tweets both in english and german were considered. However, since the API of Twitter is restricted, only one language was used at the time. In this sense, one from the lines ' search_results = twitter_api.search.tweets(q=q, count=count, lang=\"de\")' and 'search_results = twitter_api.search.tweets(q=q, count=count, lang=\"en\") is commented at the moment of execution. One hour later, when the limit of the API is reset, the code is run again switching the commented and uncommented lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Set this variable to a trending topic, \n",
    "# or anything else for that matter. The example query below\n",
    "# was a trending topic when this content was being developed\n",
    "# and is used throughout the remainder of this chapter.\n",
    "\n",
    "# A UTF-8, URL-encoded search query of 500 characters maximum, including operators.\n",
    "# URL Encoding is used when placing text in a query string \n",
    "# to avoid it being confused with the URL itself.\n",
    "\n",
    "tweets = {} #This dictionary will have information on each trending topic. The keys will be the trends themselves, and the values will be subdictionaries with the tweet texts, screen names, hashtags and tokenized texts (lists of words in the text)\n",
    "\n",
    "for trending_topic in trends_to_save: \n",
    "\n",
    "    try:\n",
    "        q = trending_topic\n",
    "\n",
    "        # number of returned tweets\n",
    "        count = 100\n",
    "\n",
    "        # Import unquote to prevent url encoding errors in next_results\n",
    "        from urllib.parse import unquote\n",
    "\n",
    "        # See https://dev.twitter.com/rest/reference/get/search/tweets\n",
    "        #print(q)\n",
    "        #search_results = twitter_api.search.tweets(q=q, count=count, lang=\"en\")\n",
    "        search_results = twitter_api.search.tweets(q=q, count=count, lang=\"de\")\n",
    "        statuses = search_results['statuses']\n",
    "        # Iterate through 5 more batches of results by following the cursor\n",
    "        for _ in range(5):\n",
    "            #print('Length of statuses', len(statuses))\n",
    "            try:\n",
    "                next_results = search_results['search_metadata']['next_results']\n",
    "                # No more results when next_results doesn't exist;\n",
    "                # get the actual exception object as the variable e\n",
    "            except KeyError as e:  \n",
    "                break\n",
    "                \n",
    "            # Create a dictionary from next_results\n",
    "            kwargs = dict([ kv.split('=') for kv in unquote(next_results[1:]).split(\"&\") ])\n",
    "            #use of *args and **kwargs for expressing arbitrary arguments and keyword arguments\n",
    "            search_results = twitter_api.search.tweets(**kwargs) \n",
    "            statuses += search_results['statuses']\n",
    "\n",
    "        # Show one sample search result by slicing the list...\n",
    "        #print(json.dumps(statuses[0], indent=1))\n",
    "\n",
    "        #Save the data\n",
    "        status_texts = [status['text'] \n",
    "                 for status in statuses]\n",
    "        # screen name is the twitter user name of an account\n",
    "        screen_names = [ user_mention['screen_name'] \n",
    "                        for status in statuses\n",
    "                            for user_mention in status['entities']['user_mentions'] ]\n",
    "\n",
    "        hashtags = [ hashtag['text'] \n",
    "                    for status in statuses\n",
    "                        for hashtag in status['entities']['hashtags'] ]\n",
    "\n",
    "        # Compute a collection of all words from all tweets\n",
    "        words = [ w \n",
    "                for t in status_texts \n",
    "                    for w in t.split() ]\n",
    "\n",
    "        tweets.update({trending_topic:{'text':status_texts, 'screen_names': screen_names, 'hastags':hashtags, 'words':words}})\n",
    "\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#NordStream2</th>\n",
       "      <th>#Merz</th>\n",
       "      <th>#Sozialtourismus</th>\n",
       "      <th>Pipelines</th>\n",
       "      <th>Sabotage</th>\n",
       "      <th>Wochenteiler</th>\n",
       "      <th>#ENGGER</th>\n",
       "      <th>Ostsee</th>\n",
       "      <th>Kai Pflaume</th>\n",
       "      <th>Entschuldigung</th>\n",
       "      <th>...</th>\n",
       "      <th>Biden</th>\n",
       "      <th>Faschismus</th>\n",
       "      <th>Wortwahl</th>\n",
       "      <th>Bergfest</th>\n",
       "      <th>Methan</th>\n",
       "      <th>Röhren</th>\n",
       "      <th>explosionen</th>\n",
       "      <th>Faschisten</th>\n",
       "      <th>Ariel</th>\n",
       "      <th>Amerikaner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>text</th>\n",
       "      <td>[RT @eventhoryzen: Amerikanische Geheimdienste...</td>\n",
       "      <td>[RT @heuteshow: Strack-Zimmermann über #Merz: ...</td>\n",
       "      <td>[RT @shengfui: Richtigstellung: In einem vorhe...</td>\n",
       "      <td>[RT @JueKarl: Was aus #Nordstream1 und #Nordst...</td>\n",
       "      <td>[RT @winkelsdorf: Mal etwas Hintergrund zur Sa...</td>\n",
       "      <td>[RT @kristina7968: Guten Morgen Ihr Lieben! Ei...</td>\n",
       "      <td>[RT @NrwRecherche: Deutsche Neonazis bei Lände...</td>\n",
       "      <td>[RT @Dt_Pl_Inst: Neue Ostsee-Pipeline: „Die Är...</td>\n",
       "      <td>[Tim Apfel und Kai Pflaume dass ich das noch e...</td>\n",
       "      <td>[RT @nouripour: Ihre Entschuldigung in allen E...</td>\n",
       "      <td>...</td>\n",
       "      <td>[@pkbrln @AliBengali15 Ich glaube, Sie machen ...</td>\n",
       "      <td>[RT @DennisKBerlin: Kann \"wenn der Faschismus ...</td>\n",
       "      <td>[RT @astefanowitsch: Es geht nicht darum, ob d...</td>\n",
       "      <td>[Bergfest mit Dinos! 🎮Ohne💩hier gehts voll ab ...</td>\n",
       "      <td>[@L_Bednarz Es wird in die Atmosphäre entweich...</td>\n",
       "      <td>[@AlexWallasch Vor Bornholm, weit weg von der ...</td>\n",
       "      <td>[RT @Anna_Lena2022: Explosionen von Nord Strea...</td>\n",
       "      <td>[@focusonline Schamlos ist, dass der Focus die...</td>\n",
       "      <td>[RT @happilyintheam: erst Bibi &amp;amp; Julian un...</td>\n",
       "      <td>[RT @MarkusL32078761: Politik und Medien schei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>screen_names</th>\n",
       "      <td>[eventhoryzen, nikitheblogger, SteffenKotre, P...</td>\n",
       "      <td>[heuteshow, heuteshow, heuteshow, heuteshow, e...</td>\n",
       "      <td>[shengfui, E_Beiersdorfer, heuteshow, heutesho...</td>\n",
       "      <td>[JueKarl, rebew_lexa, DrLuetke, theotherphilip...</td>\n",
       "      <td>[winkelsdorf, harzhorn, rebew_lexa, DrLuetke, ...</td>\n",
       "      <td>[kristina7968, KWunsam, derleugner, Gertie8002...</td>\n",
       "      <td>[NrwRecherche, Tiefimwesten77, RubenGerczi, fc...</td>\n",
       "      <td>[Dt_Pl_Inst, AlexWallasch, PeterBorbe, welt, B...</td>\n",
       "      <td>[applefan81, NiklasHennings, vondrueben_, b00g...</td>\n",
       "      <td>[nouripour, BuchheitMarkus, Johann_v_d_Bron, J...</td>\n",
       "      <td>...</td>\n",
       "      <td>[pkbrln, AliBengali15, DerOhneNAMEN3, Handlest...</td>\n",
       "      <td>[DennisKBerlin, GeorgDiez1, StrickSimon, elhot...</td>\n",
       "      <td>[astefanowitsch, Freddi_DE, nikitheblogger, Ba...</td>\n",
       "      <td>[ClancysSon, BOO_ZerO1, Sanny11468, CharlyM201...</td>\n",
       "      <td>[L_Bednarz, Leelah1, florianaigner, bund_net, ...</td>\n",
       "      <td>[AlexWallasch, grndmstrfesxh, MuellerTadzio, w...</td>\n",
       "      <td>[Anna_Lena2022, Anna_Lena2022, sonneundmars, B...</td>\n",
       "      <td>[focusonline, derspiegel, peteralthaus, Lam3th...</td>\n",
       "      <td>[happilyintheam, dviVerpackung, Team_Luftwaffe...</td>\n",
       "      <td>[MarkusL32078761, docknack, MarkusL32078761, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hastags</th>\n",
       "      <td>[NordStream2, NordStream2, Druckabfall, NordSt...</td>\n",
       "      <td>[Merz, Merz, Merz, Merz, Sozialtourismus, Merz...</td>\n",
       "      <td>[Merz, Merz, Merz, Correctiv, Sozialtourismus,...</td>\n",
       "      <td>[Nordstream1, Nordstream2, Nordstream, BalticP...</td>\n",
       "      <td>[Nordstream, Nordstream, BalticPipe, VonDerLey...</td>\n",
       "      <td>[StarWars, Andor, Wochenteiler, putin, krieg, ...</td>\n",
       "      <td>[ENGGER, ENGGER, ENGGER, NationsLeague, Kane, ...</td>\n",
       "      <td>[Nordstream1, NordStream2, Sabotage, NordStrea...</td>\n",
       "      <td>[U, Baltic, Weihnachtsbeleuchtung, Ende, NordS...</td>\n",
       "      <td>[VonDerLeyen, Italien, U, Baltic, Weihnachtsbe...</td>\n",
       "      <td>...</td>\n",
       "      <td>[Druckabfall, Scholz, Nordstream2, Biden, Bide...</td>\n",
       "      <td>[Faschismus, CDU, CSU, Italien, Faschisten, Me...</td>\n",
       "      <td>[Erdogan, Bundestag, Merz, Erdogan, Bundestag,...</td>\n",
       "      <td>[StarCitizen, StarCitizen, bergfest, Bergfest,...</td>\n",
       "      <td>[Methan, CO2, Klimawandel, NS1, Methan, CO2, M...</td>\n",
       "      <td>[NordStream2, Nordstream, Putin, NordStream2, ...</td>\n",
       "      <td>[NordStream2, PKGr, Sabotage, Kriegserklärung,...</td>\n",
       "      <td>[Friedensdemo, Friedensdemo, Feminism, Feminis...</td>\n",
       "      <td>[Ariel, Lenor, FCBayern, Ariel, Nowplaying, MO...</td>\n",
       "      <td>[Amerikaner, Nordstream, Sanktionen, pipelines...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>words</th>\n",
       "      <td>[RT, @eventhoryzen:, Amerikanische, Geheimdien...</td>\n",
       "      <td>[RT, @heuteshow:, Strack-Zimmermann, über, #Me...</td>\n",
       "      <td>[RT, @shengfui:, Richtigstellung:, In, einem, ...</td>\n",
       "      <td>[RT, @JueKarl:, Was, aus, #Nordstream1, und, #...</td>\n",
       "      <td>[RT, @winkelsdorf:, Mal, etwas, Hintergrund, z...</td>\n",
       "      <td>[RT, @kristina7968:, Guten, Morgen, Ihr, Liebe...</td>\n",
       "      <td>[RT, @NrwRecherche:, Deutsche, Neonazis, bei, ...</td>\n",
       "      <td>[RT, @Dt_Pl_Inst:, Neue, Ostsee-Pipeline:, „Di...</td>\n",
       "      <td>[Tim, Apfel, und, Kai, Pflaume, dass, ich, das...</td>\n",
       "      <td>[RT, @nouripour:, Ihre, Entschuldigung, in, al...</td>\n",
       "      <td>...</td>\n",
       "      <td>[@pkbrln, @AliBengali15, Ich, glaube,, Sie, ma...</td>\n",
       "      <td>[RT, @DennisKBerlin:, Kann, \"wenn, der, Faschi...</td>\n",
       "      <td>[RT, @astefanowitsch:, Es, geht, nicht, darum,...</td>\n",
       "      <td>[Bergfest, mit, Dinos!, 🎮Ohne💩hier, gehts, vol...</td>\n",
       "      <td>[@L_Bednarz, Es, wird, in, die, Atmosphäre, en...</td>\n",
       "      <td>[@AlexWallasch, Vor, Bornholm,, weit, weg, von...</td>\n",
       "      <td>[RT, @Anna_Lena2022:, Explosionen, von, Nord, ...</td>\n",
       "      <td>[@focusonline, Schamlos, ist,, dass, der, Focu...</td>\n",
       "      <td>[RT, @happilyintheam:, erst, Bibi, &amp;amp;, Juli...</td>\n",
       "      <td>[RT, @MarkusL32078761:, Politik, und, Medien, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   #NordStream2  \\\n",
       "text          [RT @eventhoryzen: Amerikanische Geheimdienste...   \n",
       "screen_names  [eventhoryzen, nikitheblogger, SteffenKotre, P...   \n",
       "hastags       [NordStream2, NordStream2, Druckabfall, NordSt...   \n",
       "words         [RT, @eventhoryzen:, Amerikanische, Geheimdien...   \n",
       "\n",
       "                                                          #Merz  \\\n",
       "text          [RT @heuteshow: Strack-Zimmermann über #Merz: ...   \n",
       "screen_names  [heuteshow, heuteshow, heuteshow, heuteshow, e...   \n",
       "hastags       [Merz, Merz, Merz, Merz, Sozialtourismus, Merz...   \n",
       "words         [RT, @heuteshow:, Strack-Zimmermann, über, #Me...   \n",
       "\n",
       "                                               #Sozialtourismus  \\\n",
       "text          [RT @shengfui: Richtigstellung: In einem vorhe...   \n",
       "screen_names  [shengfui, E_Beiersdorfer, heuteshow, heutesho...   \n",
       "hastags       [Merz, Merz, Merz, Correctiv, Sozialtourismus,...   \n",
       "words         [RT, @shengfui:, Richtigstellung:, In, einem, ...   \n",
       "\n",
       "                                                      Pipelines  \\\n",
       "text          [RT @JueKarl: Was aus #Nordstream1 und #Nordst...   \n",
       "screen_names  [JueKarl, rebew_lexa, DrLuetke, theotherphilip...   \n",
       "hastags       [Nordstream1, Nordstream2, Nordstream, BalticP...   \n",
       "words         [RT, @JueKarl:, Was, aus, #Nordstream1, und, #...   \n",
       "\n",
       "                                                       Sabotage  \\\n",
       "text          [RT @winkelsdorf: Mal etwas Hintergrund zur Sa...   \n",
       "screen_names  [winkelsdorf, harzhorn, rebew_lexa, DrLuetke, ...   \n",
       "hastags       [Nordstream, Nordstream, BalticPipe, VonDerLey...   \n",
       "words         [RT, @winkelsdorf:, Mal, etwas, Hintergrund, z...   \n",
       "\n",
       "                                                   Wochenteiler  \\\n",
       "text          [RT @kristina7968: Guten Morgen Ihr Lieben! Ei...   \n",
       "screen_names  [kristina7968, KWunsam, derleugner, Gertie8002...   \n",
       "hastags       [StarWars, Andor, Wochenteiler, putin, krieg, ...   \n",
       "words         [RT, @kristina7968:, Guten, Morgen, Ihr, Liebe...   \n",
       "\n",
       "                                                        #ENGGER  \\\n",
       "text          [RT @NrwRecherche: Deutsche Neonazis bei Lände...   \n",
       "screen_names  [NrwRecherche, Tiefimwesten77, RubenGerczi, fc...   \n",
       "hastags       [ENGGER, ENGGER, ENGGER, NationsLeague, Kane, ...   \n",
       "words         [RT, @NrwRecherche:, Deutsche, Neonazis, bei, ...   \n",
       "\n",
       "                                                         Ostsee  \\\n",
       "text          [RT @Dt_Pl_Inst: Neue Ostsee-Pipeline: „Die Är...   \n",
       "screen_names  [Dt_Pl_Inst, AlexWallasch, PeterBorbe, welt, B...   \n",
       "hastags       [Nordstream1, NordStream2, Sabotage, NordStrea...   \n",
       "words         [RT, @Dt_Pl_Inst:, Neue, Ostsee-Pipeline:, „Di...   \n",
       "\n",
       "                                                    Kai Pflaume  \\\n",
       "text          [Tim Apfel und Kai Pflaume dass ich das noch e...   \n",
       "screen_names  [applefan81, NiklasHennings, vondrueben_, b00g...   \n",
       "hastags       [U, Baltic, Weihnachtsbeleuchtung, Ende, NordS...   \n",
       "words         [Tim, Apfel, und, Kai, Pflaume, dass, ich, das...   \n",
       "\n",
       "                                                 Entschuldigung  ...  \\\n",
       "text          [RT @nouripour: Ihre Entschuldigung in allen E...  ...   \n",
       "screen_names  [nouripour, BuchheitMarkus, Johann_v_d_Bron, J...  ...   \n",
       "hastags       [VonDerLeyen, Italien, U, Baltic, Weihnachtsbe...  ...   \n",
       "words         [RT, @nouripour:, Ihre, Entschuldigung, in, al...  ...   \n",
       "\n",
       "                                                          Biden  \\\n",
       "text          [@pkbrln @AliBengali15 Ich glaube, Sie machen ...   \n",
       "screen_names  [pkbrln, AliBengali15, DerOhneNAMEN3, Handlest...   \n",
       "hastags       [Druckabfall, Scholz, Nordstream2, Biden, Bide...   \n",
       "words         [@pkbrln, @AliBengali15, Ich, glaube,, Sie, ma...   \n",
       "\n",
       "                                                     Faschismus  \\\n",
       "text          [RT @DennisKBerlin: Kann \"wenn der Faschismus ...   \n",
       "screen_names  [DennisKBerlin, GeorgDiez1, StrickSimon, elhot...   \n",
       "hastags       [Faschismus, CDU, CSU, Italien, Faschisten, Me...   \n",
       "words         [RT, @DennisKBerlin:, Kann, \"wenn, der, Faschi...   \n",
       "\n",
       "                                                       Wortwahl  \\\n",
       "text          [RT @astefanowitsch: Es geht nicht darum, ob d...   \n",
       "screen_names  [astefanowitsch, Freddi_DE, nikitheblogger, Ba...   \n",
       "hastags       [Erdogan, Bundestag, Merz, Erdogan, Bundestag,...   \n",
       "words         [RT, @astefanowitsch:, Es, geht, nicht, darum,...   \n",
       "\n",
       "                                                       Bergfest  \\\n",
       "text          [Bergfest mit Dinos! 🎮Ohne💩hier gehts voll ab ...   \n",
       "screen_names  [ClancysSon, BOO_ZerO1, Sanny11468, CharlyM201...   \n",
       "hastags       [StarCitizen, StarCitizen, bergfest, Bergfest,...   \n",
       "words         [Bergfest, mit, Dinos!, 🎮Ohne💩hier, gehts, vol...   \n",
       "\n",
       "                                                         Methan  \\\n",
       "text          [@L_Bednarz Es wird in die Atmosphäre entweich...   \n",
       "screen_names  [L_Bednarz, Leelah1, florianaigner, bund_net, ...   \n",
       "hastags       [Methan, CO2, Klimawandel, NS1, Methan, CO2, M...   \n",
       "words         [@L_Bednarz, Es, wird, in, die, Atmosphäre, en...   \n",
       "\n",
       "                                                         Röhren  \\\n",
       "text          [@AlexWallasch Vor Bornholm, weit weg von der ...   \n",
       "screen_names  [AlexWallasch, grndmstrfesxh, MuellerTadzio, w...   \n",
       "hastags       [NordStream2, Nordstream, Putin, NordStream2, ...   \n",
       "words         [@AlexWallasch, Vor, Bornholm,, weit, weg, von...   \n",
       "\n",
       "                                                    explosionen  \\\n",
       "text          [RT @Anna_Lena2022: Explosionen von Nord Strea...   \n",
       "screen_names  [Anna_Lena2022, Anna_Lena2022, sonneundmars, B...   \n",
       "hastags       [NordStream2, PKGr, Sabotage, Kriegserklärung,...   \n",
       "words         [RT, @Anna_Lena2022:, Explosionen, von, Nord, ...   \n",
       "\n",
       "                                                     Faschisten  \\\n",
       "text          [@focusonline Schamlos ist, dass der Focus die...   \n",
       "screen_names  [focusonline, derspiegel, peteralthaus, Lam3th...   \n",
       "hastags       [Friedensdemo, Friedensdemo, Feminism, Feminis...   \n",
       "words         [@focusonline, Schamlos, ist,, dass, der, Focu...   \n",
       "\n",
       "                                                          Ariel  \\\n",
       "text          [RT @happilyintheam: erst Bibi &amp; Julian un...   \n",
       "screen_names  [happilyintheam, dviVerpackung, Team_Luftwaffe...   \n",
       "hastags       [Ariel, Lenor, FCBayern, Ariel, Nowplaying, MO...   \n",
       "words         [RT, @happilyintheam:, erst, Bibi, &amp;, Juli...   \n",
       "\n",
       "                                                     Amerikaner  \n",
       "text          [RT @MarkusL32078761: Politik und Medien schei...  \n",
       "screen_names  [MarkusL32078761, docknack, MarkusL32078761, w...  \n",
       "hastags       [Amerikaner, Nordstream, Sanktionen, pipelines...  \n",
       "words         [RT, @MarkusL32078761:, Politik, und, Medien, ...  \n",
       "\n",
       "[4 rows x 30 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df = pd.DataFrame(tweets) #Putting the tweet information in a DataFrame\n",
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the tweets retrieved for the current datetime\n",
    "now = datetime.datetime.now().strftime(\"%m.%d.%Y_%Hh\")\n",
    "name = 'GermanyTrends_{}.xlsx'.format(now)\n",
    "tweets_df.to_excel(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7d9ebe34134f29bd8677082684440d95d2376325106a2427c4f85e8c3b3f09fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
